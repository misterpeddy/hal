import ffmpeg
import librosa as rosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import sys
import os

from IPython.display import Audio as IAudio
from IPython.display import display as Idisplay

from demucs import separate as dm_separate

from hal import io_utils
from hal.audio import analyzers

_FIG_SIZE = (12, 3)
_VID_FRAME_RATE = 24

class Track:
  def __init__(self, path, name, autogenerated=True):
    self.path = os.path.abspath(path)
    self.autogenerated = autogenerated
    self.name = name
    self.audio = self.sr = self._chromagram = self._onsets = None
    self._prepare()

  def _prepare(self):
    self.audio, self.sr = rosa.load(self.path)
    self._chromagram = analyzers.chroma(self)
    self._low_onsets = analyzers.onsets(self, fmax=200)
    self._high_onsets = analyzers.onsets(self, fmin=500)

  def show_wave(self):
    plt.figure(figsize=_FIG_SIZE)
    rosa.display.waveshow(self.audio, self.sr, x_axis='s')
    plt.title(self.name)
    plt.tight_layout()
    plt.show()

  def show_chromagram(self):
    plt.figure(figsize=_FIG_SIZE)
    rosa.display.specshow(self._chromagram.numpy().T, sr=_VID_FRAME_RATE, y_axis='chroma', x_axis='frames')
    plt.tight_layout()
    plt.show()

  def show_onsets(self):
    plt.figure(figsize=_FIG_SIZE)
    plt.plot(self._low_onsets, label='Low Onsets')
    plt.plot(self._high_onsets, label='High Onsets')
    plt.legend(frameon=True, framealpha=0.75)
    plt.tight_layout()
    plt.show()

  def show_player(self):
    Idisplay(IAudio(data=self.audio, rate=self.sr))


class Audio:

  def __init__(self, filename, autogen_stems=False):
    self.source_file = os.path.abspath(filename)
    self.autogen_stems = autogen_stems
    self.tracks = {}
    source_name = io_utils.name_from_path(filename)
    self.tracks['source'] = Track(filename, source_name, autogenerated=False)
    self.gen_dir = os.path.join(
      io_utils.create_cache_dir('audio'),
      io_utils.name_from_path(filename))
    self.gen_dir = io_utils.next_dir(self.gen_dir)

    if autogen_stems:
      self.generate_stems()

  def cut(self, start, stop):
    """Cuts audio from start to stop, both provided in seconds."""
    assert stop > start, '`stop` has to be greater than `start`, both in seconds.'
    output_path = io_utils.add_suffix(self.source_file, f'{start}_to_{stop}', self.gen_dir)
    (
      ffmpeg
      .input(self.source_file, ss=start, t=(stop-start))
      .output(output_path)
      .overwrite_output()
      .run(quiet=True)
    )
    return Audio(output_path, self.autogen_stems)

  def generate_stems(self):
    model_name = 'demucs_quantized'
    saved_argv = sys.argv
    sys.argv = ['', '-o={}'.format(self.gen_dir)]
    sys.argv += ['-n={}'.format(model_name)]
    sys.argv += [self.source_file]
    try:
      dm_separate.main()
    except:
      sys.argv = saved_argv
      return
    sys.argv = saved_argv
    source_name = io_utils.name_from_path(self.tracks['source'].path)
    stems_path = os.path.join(self.gen_dir, model_name, source_name)
    for f in os.listdir(stems_path):
      name = f.split(".")[0] if "." in f else f
      t = Track(os.path.join(stems_path, f), name)
      self.tracks[name] = t
